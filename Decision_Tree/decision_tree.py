# -*- coding: utf-8 -*-
"""Decision_Tree_Week6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g_w1HVru9t1YZLNGHiFPgTcAr43Uc3rn

# Data Preparation of employee dataset
"""

# Data prepartion
# Loading libraries and functions
from pandas import read_csv, get_dummies, Series, DataFrame
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# Loading the datatset
data=read_csv('/content/Emloyees.csv')

# Converting categorical variables into numeric values
# First Converting binary categorical into numeric value 0 and 1
data['PastEmployee'] = data['PastEmployee'].map({'Yes':1, 'No':0})
data['OverTime'] = data['OverTime'].map({'Yes':1,'No':0})
data['Gender'] = data['Gender'].map({'Male':1,'Female':0})

# Converting categorical variables into numeric values 0 and 1 using one hot encoding
data2=get_dummies(data, columns=['BusinessTravel', 'Department','EducationField','JobRole','MaritalStatus'])

# Seggreagating the data into X and Y features i.e., independent and dependent features
X=data2.drop('PastEmployee',axis=1) # Independent features
Y=data2['PastEmployee'] # Dependent features

# Normalization/ Standardisation of the dataset
X_scaled=StandardScaler().fit_transform(X)

# Splitting the dataset into training and testing
X_train,X_test,Y_train,Y_test= train_test_split(X_scaled,Y, test_size=0.3,random_state=1)

# Balancing the dataset using SMOTE technique
X_train, Y_train=SMOTE(random_state=1).fit_resample(X_train,Y_train) # Balancing the class labels

"""# Decision Trees"""

from sklearn import tree

dec_tree= tree.DecisionTreeClassifier(criterion='entropy',max_depth=5) # Decision Tree Classifier Building

dec_tree.fit(X_train,Y_train) # Fitting decision tree classifier to the training set

Y_pred=dec_tree.predict(X_test) # Predicted Y value on the test dataset

"""# Evaluating the performace of the model: Decision tree"""

from sklearn import metrics
Accuracy= metrics.accuracy_score(Y_test,Y_pred) # Calculating the accuracy of the model build
Recall= metrics.recall_score(Y_test,Y_pred) # Calculating the recall of the model build
Precision= metrics.precision_score(Y_test,Y_pred) # Calculating the precision of the model build
print('Accuracy:', Accuracy)
print('Recall:', Recall)
print('Precision:', Precision)

conf_mat= metrics.confusion_matrix(Y_test,Y_pred) # Confusion matrix
conf_mat

"""# Validation of the Model build: decision tree"""

from sklearn.model_selection import GridSearchCV

dec_tree2= tree.DecisionTreeClassifier(criterion='entropy',random_state=1) # Decision Tree Classifier Building

depth={'max_depth': [2,4,5,6,8,9,10,12,25,28,30,36]} # Grid of max_depth parameter length = 12

grid_search=GridSearchCV(estimator=dec_tree2,param_grid=depth,scoring='precision',cv=5)

grid_search.fit(X_train,Y_train) # Fitting decision tree classifier to the training set
best_depth= grid_search.best_params_ # Selecting the optimal parameter max_depth
print(best_depth)

# Refitting the model with the optimal/best max_depth parameter selected based on the precision
dec_tree_best_depth= tree.DecisionTreeClassifier(criterion='entropy',max_depth=8) # Decision Tree Classifier Building
dec_tree_best_depth.fit(X_train,Y_train) # Fitting decision tree classifier to the training set
Y_pred=dec_tree_best_depth.predict(X_test) # Predicted Y value on the test dataset

from sklearn import metrics
Accuracy= metrics.accuracy_score(Y_test,Y_pred) # Calculating the accuracy of the model build
Recall= metrics.recall_score(Y_test,Y_pred) # Calculating the recall of the model build
Precision= metrics.precision_score(Y_test,Y_pred) # Calculating the precision of the model build
print('Accuracy:', Accuracy)
print('Recall:', Recall)
print('Precision:', Precision)

"""# Important features/variables"""

# Selecting the optimal features
dec_tree_best_depth_impt_feat= tree.DecisionTreeClassifier(criterion='entropy',max_depth=8, random_state=1)
dec_tree_best_depth_impt_feat.fit(X_train,Y_train)
Y_pred_impt_feat=dec_tree_best_depth_impt_feat.predict(X_test)
imp_features=Series(dec_tree_best_depth_impt_feat.feature_importances_,index=list(X)).sort_values(ascending=False)
print(imp_features)

# Getting the important features in the dataset
X2=data2[['OverTime','MaritalStatus_Single','EnvironmentSatisfaction','MonthlyIncome','Age']]

# Normalization/ Standardisation of the new dataset with important features
X_scaled2=StandardScaler().fit_transform(X2)


# Dataset into training and testing
X_train,X_test,Y_train,Y_test= train_test_split(X_scaled2,Y, test_size=0.3,random_state=1)

# Balancing the dataset using SMOTE technique
X_train, Y_train=SMOTE(random_state=1).fit_resample(X_train,Y_train) # Balancing the class labels

# Fitting decision tree on important features
from sklearn import tree
dec_tree_best_depth_impt_feat= tree.DecisionTreeClassifier(criterion='entropy',max_depth=8,random_state=1)
dec_tree_best_depth_impt_feat.fit(X_train,Y_train)
Y_pred_impt_feat=dec_tree_best_depth_impt_feat.predict(X_test)

# Selecting the max_depth parameter
depth={'max_depth': [2,6,10,12,25,28,30,36,38,40,52]} # Grid of max_depth parameter length = 8

grid_search=GridSearchCV(estimator=dec_tree_best_depth_impt_feat,param_grid=depth,scoring='precision',cv=10)

grid_search.fit(X_train,Y_train) # Fitting decision tree classifier to the training set
best_depth= grid_search.best_params_ # Selecting the optimal parameter max_depth
print(best_depth)

# Fitting decision tree with optimal max_depth parameter and important features
from sklearn import tree
dec_tree_best_depth_impt_feat= tree.DecisionTreeClassifier(criterion='entropy',max_depth=36)
dec_tree_best_depth_impt_feat.fit(X_train,Y_train)
Y_pred_impt_feat=dec_tree_best_depth_impt_feat.predict(X_test)


# Calculating the accuracy, recall and precision of the decision tree with optimal max_depth parameter and important features
from sklearn import metrics
Accuracy= metrics.accuracy_score(Y_test,Y_pred_impt_feat) # Calculating the accuracy of the model build
Recall= metrics.recall_score(Y_test,Y_pred_impt_feat) # Calculating the recall of the model build
Precision= metrics.precision_score(Y_test,Y_pred_impt_feat) # Calculating the precision of the model build
print('Accuracy:', Accuracy)
print('Recall:', Recall)
print('Precision:', Precision)

# Calculating confusion matrix of the decision tree with optimal max_depth parameter and important features
conf_mat= metrics.confusion_matrix(Y_test,Y_pred_impt_feat) # Confusion matrix
print(conf_mat)