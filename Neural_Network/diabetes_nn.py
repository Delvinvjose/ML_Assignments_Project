# -*- coding: utf-8 -*-
"""Diabetes_NN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bLxrtXNInJsgX4IJmJvOaF0tdVoNvxwQ

### **Tutorial**: Building Your First Neural Network with TensorFlow

Introduction

Welcome to this tutorial where you’ll learn how to build your first neural network using TensorFlow, a powerful library for machine learning. We’ll use a dataset on diabetes to predict whether patients show signs of diabetes based on certain measurements.

**Step 1: Load and Explore the Data**

First, we import necessary libraries and load the data:
"""

import pandas as pd
import tensorflow as tf
import numpy as np

# Load the dataset
diabetes_data = pd.read_csv('/content/Diabetes_Data.csv')

# Take a look at the first few rows
diabetes_data.head()

diabetes_data.info()

diabetes_data.isnull().sum()

diabetes_data.duplicated().sum()

diabetes_data = diabetes_data.dropna()

diabetes_data['Outcome'].value_counts() #33% yes, 67% no

"""Take a moment to understand the structure of your data, the features, and what each might represent.



**Step 2: Preprocess the Data**

Before we feed the data into our neural network, we need to preprocess it. This step typically includes normalizing the data and splitting it into training and test sets:
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Separate features and targets
X = diabetes_data.drop('Outcome', axis=1)
y = diabetes_data['Outcome']

# Normalize the feature data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42) #20% test set

"""Normalization ensures that our neural network treats all features equally.

**Step 3: Build the Neural Network Model**

When building a neural network, we are essentially constructing a computational graph that can learn from data. In Keras, this process is made simple with the Sequential model, which allows us to stack layers in a linear fashion, with each layer having neurons (also called nodes) that process incoming data, apply weights and biases, and pass the results to the next layer.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Define the model
model = Sequential([
    Dense(16, activation='relu',input_shape=(X_train.shape[1],) ), # Input layer
    Dense(8, activation='relu'),      # Hidden layer
    Dense(1, activation='sigmoid') # Output layer
])
model.summary()

"""Here, **Sequential** creates a linear stack of layers. We add two **Dense** hidden layers with the 'relu' activation function and one output layer with the 'sigmoid' activation function, which is suitable for binary classification tasks.

Dense layers are the basic building blocks of neural networks in Keras. A Dense layer is fully connected, meaning each neuron in the layer receives input from all neurons of the previous layer.

`Dense(16, activation='relu', input_shape=(X_train.shape[1],))`

- This line creates the first layer of the network, which
also serves as the input layer.

- 16 denotes the number of neurons in this layer. The choice of 16 is somewhat arbitrary and is usually determined by experimentation.

- activation='relu' refers to the activation function used by each neuron in this layer. ReLU (Rectified Linear Unit) is a common activation function that introduces non-linearity into the model, allowing it to learn more complex patterns.

- input_shape=(X_train.shape[1],) specifies the shape of the input data that the model should expect. In this case, it's the number of features from the training set.

`Dense(8, activation='relu')`

- The second line adds another dense layer with 8 neurons, also with ReLU activation.
- This is the second hidden layer, and it allows the network to begin to hierarchically learn more complex representations of the input data.

`Dense(1, activation='sigmoid')`

- Finally, we add the output layer with a single neuron because we are performing binary classification (diabetes or no diabetes).
- The activation='sigmoid' function is used because it outputs a value between 0 and 1, representing the probability that the input belongs to the positive class (in this case, having diabetes). For binary outcomes, this activation function is ideal.

**Model Architecture Summary**

Once these layers are defined, we can think of the model architecture as follows:

- Input data is fed into the first layer, which has 16 neurons.
- Each neuron in the first layer processes the input data, applies a weight and bias, and the result is passed through the ReLU activation function.
- The outputs from the first layer are then fed as inputs to the second layer, which does a similar processing with its 8 neurons.
- Finally, the processed data from the second hidden layer is passed to the output layer.
- The single neuron in the output layer takes these inputs and applies its own weights and bias. The result is passed through the sigmoid activation function to yield the final prediction probability.

By stacking these layers, we have constructed a simple feedforward neural network that is capable of learning from our data to make predictions. Each layer learns different aspects of the data, with earlier layers generally learning more generic features and deeper layers learning more specific ones.

**Step 4: Compile the Model**

Next, we compile the model with an optimizer, a loss function, and a metric:
"""

from tensorflow.keras.losses import BinaryCrossentropy

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""Optimizer

- The optimizer is an algorithm or method used to change the attributes of the neural network, such as weights and learning rate, to reduce the losses. Optimizers help to minimize (or maximize) an objective function, which is often the error between the predicted values and the actual values.

`optimizer='adam'`

- Adam stands for Adaptive Moment Estimation. It's an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications.
- It combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.
- Adam is computationally efficient, has little memory requirements, is invariant to diagonal rescale of the gradients, and is well suited for problems that are large in terms of data and/or parameters.

Loss Function

The loss function, or cost function, measures how well the model does on the training data. It's a method to evaluate how well the algorithm models the dataset. If predictions deviate too far from actual results, loss function output is higher. The goal of our training process is to minimize this value.

For binary classification problems like ours, where the output can be either 0 or 1, we use binary cross-entropy:

`loss='binary_crossentropy'`

- Binary cross-entropy is a loss function used for binary classification problems. It compares each of the predicted probabilities to the actual class output, which can be either 0 or 1. It penalizes the probability based on how far it is from the actual label.
- It’s suitable for binary labels prediction, which matches our task of predicting whether a patient has diabetes (1) or not (0).

Metrics

Metrics are used to monitor the training and testing steps. They are similar to loss functions, except that the results from evaluating a metric are not used when training the model.

In our example, we are interested in the accuracy metric:


`metrics=['accuracy']`

- Accuracy calculates how often predictions equal labels. It is a common metric for classification problems.
- It gives us a straightforward indication of the performance of the model - the fraction of the total samples that were correctly classified.

**Step 5**: Train the Model

With our model built and compiled, it’s time to train it with our data:
"""

history = model.fit(X_train, y_train, epochs=200, validation_split=0.2)

"""The **fit** function trains the model for a specified number of epochs with a fraction of the training data held back for validation.

- X_train: The input features of the training data.
- y_train: The actual target outputs (labels) of the training data.
- epochs=200: This specifies the number of times the learning algorithm will work through the entire training dataset. An epoch is one complete pass through the dataset.
- validation_split=0.2: This tells the method to hold back 20% of the training data to use as validation data. The model will not train on this data, but it will report the loss and any other metrics specified in the compile step, such as accuracy, on this data.

What Happens During Training?

During training, the model makes predictions (forward pass) on the training data, compares the predictions to the actual targets using the loss function defined earlier, and calculates the error. The optimizer algorithm then makes adjustments to the weights of the neurons in the network to minimize this error (backward pass). This process is known as **backpropagation**.

The **epochs** parameter controls how many times this process is repeated. During each epoch, the data is shuffled to ensure the model doesn't learn the order of the training.

Validation Split

By setting a **validation_split**, we reserve a part of the training data to evaluate the model's performance on unseen data. This helps in monitoring for overfitting. Overfitting occurs when a model learns the training data too well, including noise and false patterns that do not apply to new data.

Monitoring Training

The **fit** method returns a **History** object which contains the record of loss and accuracy values at the end of each epoch both on the training and validation datasets. These metrics are what we will later visualize to understand the learning process.

**Step 6**: Evaluate the Model

After training, we evaluate our model's performance on the test data:
"""

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test accuracy: {accuracy*100:.2f}%")

# Example of plotting training history
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
#plt.ylim([0, 1])
plt.legend(loc='lower right')

from matplotlib import pyplot
_, train_acc = model.evaluate(X_train, y_train, verbose = 0)
_, test_acc = model.evaluate(X_test, y_test, verbose = 0)
print('Train: %.3f, Test: %.3f' %(train_acc, test_acc))

pyplot.subplot(211)
pyplot.title('Loss')
pyplot.plot(history.history['loss'], label = 'train')
pyplot.plot(history.history['val_loss'], label='validation')
pyplot.legend()

pyplot.subplot(212)
pyplot.title('Accuracy')
pyplot.plot(history.history['accuracy'], label = 'train')
pyplot.plot(history.history['val_accuracy'], label='validation')
pyplot.legend()

pyplot.show()

"""**Step 7**: Make Predictions

Finally, let's use our model to make predictions:
"""

predictions = model.predict(X_test)

X_test

predictions

from sklearn.metrics import confusion_matrix, classification_report

y_pred = np.argmax(model.predict(X_test), axis = 1)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))