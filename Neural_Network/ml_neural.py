# -*- coding: utf-8 -*-
"""ml neural.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EPj1SZdxwLYUn-ZKrj6hv37Vb12IHLbg
"""

import pandas as pd
import numpy as np
import tensorflow
import sklearn

data = pd.read_csv('/content/Diabetes_Data (1).csv')

data.head()

data.info()

from re import X
X = data.drop('Outcome',axis=1)
Y = data['Outcome']

Y.value_counts()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
X_train, Y_train =SMOTE(random_state=1).fit_resample(X_train, Y_train)
X_test, Y_test =SMOTE(random_state=1).fit_resample(X_test, Y_test)



from keras.models import Sequential
from keras.layers import Dense
model = Sequential([
    Dense(16, input_dim=X_train.shape[1], activation='relu'),
    Dense(12, activation='relu'),
    Dense(1, activation='sigmoid')
])
model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=1)

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)
print(f"Test Accuracy: {accuracy*100:.2f}%")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from matplotlib import pyplot
_, train_acc = model.evaluate(X_train, Y_train, verbose = 0)
_, test_acc = model.evaluate(X_test, Y_test, verbose = 0)
print('Train: %.3f, Test: %.3f' %(train_acc, test_acc))

pyplot.subplot(211)
pyplot.title('Loss')
pyplot.plot(history.history['loss'], label = 'train')
pyplot.plot(history.history['val_loss'], label='validation')
pyplot.legend()

pyplot.subplot(212)
pyplot.title('Accuracy')
pyplot.plot(history.history['accuracy'], label = 'train')
pyplot.plot(history.history['val_accuracy'], label='validation')
pyplot.legend()

pyplot.show()

predictions = model.predict(X_test)

X_test

predictions

from sklearn.metrics import confusion_matrix, classification_report

Y_pred = np.argmax(model.predict(X_test), axis = 1)
print(confusion_matrix(Y_test, Y_pred))
print(classification_report(Y_test, Y_pred))

# !pip install scikeras

# from sklearn.model_selection import GridSearchCV
# from scikeras.wrappers import KerasClassifier

!pip install scikeras

# !pip install tensorflow scikeras

from sklearn.model_selection import GridSearchCV
from scikeras.wrappers import KerasClassifier  # Use SciKeras instead of TensorFlow's wrapper
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Function to create a model
def create_model(optimizer='adam', activation='relu'):
    model = Sequential([
        Dense(16, input_dim=X_train.shape[1], activation=activation),
        Dense(12, activation=activation),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Wrap the model with SciKeras
model = KerasClassifier(model=create_model, verbose=0)

# Define parameter grid
param_grid = {
    'batch_size': [16, 32, 64],
    'epochs': [50, 100],
    'model__optimizer': ['adam', 'rmsprop'],  # Prefix "model__" is required for SciKeras
    'model__activation': ['relu', 'tanh']
}

# Perform grid search
grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)
grid_result = grid.fit(X_train, Y_train)

# Output best parameters and score
print(f"Best parameters: {grid_result.best_params_}")
print(f"Best accuracy: {grid_result.best_score_}")